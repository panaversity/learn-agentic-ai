{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30327e3a"
      },
      "source": [
        "# ğŸš€ Exploring the openai-agents Library with Gemini\n",
        "This notebook shows how to use the openai-agents library with Gemini API to build conversational agentsâ€”covering two execution methods"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ“¦ installation"
      ],
      "metadata": {
        "id": "wd12XkqwSRxc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8U2DuZP0_1Iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4f7258-ff89-45cd-e21b-cc946eeb5156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.5/158.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ“¦ Imports"
      ],
      "metadata": {
        "id": "jL-reb6RR_H6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "OE_-gMwUDw8b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ“¦ Imports"
      ],
      "metadata": {
        "id": "MywTysH-Rn2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import asyncio\n",
        "import nest_asyncio\n",
        "\n",
        "from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel\n",
        "from agents.run import RunConfig\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "dvNo75PtD5YL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ” Step 1: Setup for Api Keys"
      ],
      "metadata": {
        "id": "uO3deejXRZw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n"
      ],
      "metadata": {
        "id": "9p1ynoc0EDCx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸŒ  Step 2: Client Setup for Connecting to **Gemini**"
      ],
      "metadata": {
        "id": "S4GITaFOP526"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "external_client:AsyncOpenAI = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model:OpenAIChatCompletionsModel = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    openai_client=external_client\n",
        ")"
      ],
      "metadata": {
        "id": "IofWknGLEHHI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ’¬  Step 3 Running Agent Synchronously"
      ],
      "metadata": {
        "id": "Upg62mcUJUB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent: Agent = Agent(name=\"Assistant\", instructions=\"You are a helpful assistant\", model=model)\n",
        "\n",
        "result:Runner = Runner.run_sync(agent, \"Hello, how are you.\")\n",
        "\n",
        "print(\"\\nCALLING AGENT\\n\")\n",
        "print(result.final_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QgfJqHZJV_M",
        "outputId": "1d33e083-8753-4098-9903-38f3d66301a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:openai.agents:OPENAI_API_KEY is not set, skipping trace export\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CALLING AGENT\n",
            "\n",
            "Hello! I don't have feelings or a physical state like humans do, but I'm functioning perfectly and ready to assist you.\n",
            "\n",
            "How are you doing today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ’¬ Step 3: Running Agent Asynchronously"
      ],
      "metadata": {
        "id": "1m8xnCs4KKG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def main():\n",
        "    agent:Agent = Agent(\n",
        "        name=\"HaikuAssistant\",\n",
        "        instructions=\"You only respond in haikus.\",\n",
        "        model=model\n",
        "    )\n",
        "\n",
        "    result:Runner = await Runner.run(agent, \"Tell me about recursion in programming.\")\n",
        "\n",
        "    print(result.final_output)\n",
        "\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())"
      ],
      "metadata": {
        "id": "jZA-iSR9KMJ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670de776-805b-440a-dc14-add533e2a625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function calls itself,\n",
            "Until a base case it finds,\n",
            "Solves in small steps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7RKgPtw2XlJs"
      }
    }
  ]
}